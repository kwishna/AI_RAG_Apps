{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13114657-dd75-422b-ba7f-6f13568303be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ffe2755-85f0-4156-8f7f-16c9c9f71d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.6)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.1.52)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (1.25.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.1.54)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (1.26.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\abc\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa21861-d047-4b06-a8c3-18fa57e1e3e4",
   "metadata": {},
   "source": [
    "# ================== LLM ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4089de60-a1c9-49d0-a649-0e302b8865f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a21024-3c5e-4d63-9aaa-af5b248f46b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in several ways:\\n\\n1. Automated testing: Langsmith can be used to write automated test scripts in various programming languages, making it easier to test different components of the software application.\\n\\n2. Test data generation: Langsmith can generate test data for different scenarios, helping testers to cover a wide range of test cases efficiently.\\n\\n3. Performance testing: Langsmith can be used to simulate a large number of users accessing the application simultaneously, helping testers to identify performance bottlenecks and improve the application's performance.\\n\\n4. Integration testing: Langsmith can be used to test the integration between different components of the application, ensuring that they work together seamlessly.\\n\\n5. Regression testing: Langsmith can help automate regression testing, allowing testers to quickly identify any new bugs introduced in the software application after changes have been made.\\n\\nOverall, Langsmith can help streamline the testing process, improve test coverage, and ensure the quality of the software application.\", response_metadata={'token_usage': {'completion_tokens': 191, 'prompt_tokens': 15, 'total_tokens': 206}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3fd31b49-c05b-4ee4-9373-875172dfe7f0-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = llm.invoke(\"how can langsmith help with testing?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2e877b-b8a4-4bdc-bf97-aaa79fb343a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith can help with testing in several ways:\\n\\n1. Automated testing: Langsmith can be used to write automated test scripts in various programming languages, making it easier to test different components of the software application.\\n\\n2. Test data generation: Langsmith can generate test data for different scenarios, helping testers to cover a wide range of test cases efficiently.\\n\\n3. Performance testing: Langsmith can be used to simulate a large number of users accessing the application simultaneously, helping testers to identify performance bottlenecks and improve the application's performance.\\n\\n4. Integration testing: Langsmith can be used to test the integration between different components of the application, ensuring that they work together seamlessly.\\n\\n5. Regression testing: Langsmith can help automate regression testing, allowing testers to quickly identify any new bugs introduced in the software application after changes have been made.\\n\\nOverall, Langsmith can help streamline the testing process, improve test coverage, and ensure the quality of the software application.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc9154-54fc-45d0-bd8d-4de0aaef00e3",
   "metadata": {},
   "source": [
    "# ================== Prompt Template ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded42c86-bb32-4d3d-82e7-f3d7c7074434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class History Researcher.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1576a824-fa80-47fa-ade5-a74dca071314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The largest animal in the world known by humans is the blue whale (Balaenoptera musculus). They can grow up to 100 feet in length and weigh as much as 200 tons. Blue whales are the largest animals ever known to have existed on Earth.', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 32, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-90f79fdc-1725-4bb3-a813-a8b6b39edd6c-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt.pipe(llm)\n",
    "chain.invoke({\"input\": \"which is the largest animal in the world known by humans?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44c40d0-dfda-473d-800c-0bfd459330c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a world class History Researcher.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "088ceb3a-0c00-416c-a2e0-5fec7ab60f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The largest animal in the world known to humans is the blue whale (Balaenoptera musculus). Blue whales can grow up to 100 feet in length and weigh as much as 200 tons. They are the largest animals to have ever lived on Earth.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 32, 'total_tokens': 86}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b347fdb6-4327-4842-a756-f85c57d671fa-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"input\": \"which is the largest animal in the world known by humans?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a284ebb-e759-48ce-aba5-a3e3179e3264",
   "metadata": {},
   "source": [
    "# ============== String Output Parser ===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37fdb11f-56fb-47c2-9de2-cf10be1a256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1f8dcd9-e512-492e-b442-6e3d53abebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9f5d4d1-6d0c-4732-b023-db1db89b0e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a powerful tool that can assist with testing in a variety of ways:\\n\\n1. Test Data Generation: Langsmith can generate synthetic test data to simulate real-world scenarios, helping to ensure comprehensive test coverage.\\n\\n2. Test Case Generation: Langsmith can automatically generate test cases based on predefined criteria, saving time and effort in manual test case creation.\\n\\n3. Test Automation: Langsmith can be integrated with testing frameworks to automate the execution of test cases, reducing the need for manual testing and improving efficiency.\\n\\n4. Regression Testing: Langsmith can help in conducting regression testing by quickly generating test cases to ensure that recent code changes have not introduced any new bugs.\\n\\n5. Performance Testing: Langsmith can simulate high volumes of user activity to test the performance and scalability of applications under different load conditions.\\n\\nOverall, Langsmith can enhance the testing process by providing valuable support in test data generation, test case creation, test automation, regression testing, and performance testing.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afaf5079-5800-433e-a56b-45d273ac034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104a29e0-ba9b-4373-9d6d-251be5dc5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813c434b-bf68-41bf-b20f-a8689204294e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\n\\nGet started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it\\'s not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãWe provide multiple ways to log traces to LangSmith. Below, we\\'ll highlight\\nhow to use traceable. See more on the Annotate code for tracing page.PythonTypeScriptimport openaifrom langsmith.wrappers import wrap_openaifrom langsmith import traceable# Auto-trace LLM calls in-contextclient = wrap_openai(openai.Client())@traceable # Auto-trace this functiondef pipeline(user_input: str):    result = client.chat.completions.create(        messages=[{\"role\": \"user\", \"content\": user_input}],        model=\"gpt-3.5-turbo\"    )    return result.choices[0].message.contentpipeline(\"Hello, world!\")# Out:  Hello there! How can I assist you today?import { OpenAI } from \"openai\";import { traceable } from \"langsmith/traceable\";import { wrapOpenAI } from \"langsmith/wrappers\";// Auto-trace LLM calls in-contextconst client = wrapOpenAI(new OpenAI());// Auto-trace this functionconst pipeline = traceable(async (user_input) => {    const result = await client.chat.completions.create({        messages: [{ role: \"user\", content: user_input }],        model: \"gpt-3.5-turbo\",    });    return result.choices[0].message.content;});await pipeline(\"Hello, world!\")// Out: Hello there! How can I assist you today?View a sample output trace.Learn more about tracing in the how-to guides.5. Run your first evaluation‚ÄãEvaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.PythonTypeScriptfrom langsmith import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators: [exactMatch],    metadata: {      version: \"1.0.0\",      revision_id: \"beta\",    },  });Learn more about evaluation in the how-to guides.Was this page helpful?NextTutorials1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2024 LangChain, Inc.\\n\\n\\n\\n', metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53b4932-5aa1-4c87-a4f8-83a84fd328c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b28fe-e223-49db-b78f-a112e7fd5c66",
   "metadata": {},
   "source": [
    "# =============== Vector Store ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689a7cce-9092-403c-a65c-6ca5841c1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f509ca-979a-4fca-97df-90512c16ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\abc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbf98426-3558-4aad-9c39-f93c942e97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=10, chunk_size=200, separators=['.'])\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a2f6cdc-c5c6-48fd-9af3-dd67813502c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72dec6ea-2a25-4419-84d7-4ee16bc3e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "175\n",
      "188\n",
      "225\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(documents[i].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "753f3371-55b2-453e-ae08-d99825ea25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3217d43f-d2ad-4cd4-8a30-9875d125854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e755d0b-9b7f-47b6-9981-7f44cdfcae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local('./vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0be441f4-7658-475b-9f31-8d1d9ca97ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_docs = vector_store.similarity_search(k=3, query=\"Purpose of langsmith\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "03d8983b-5601-447e-bbc0-5484ed61ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2985a13-c74b-4283-b5eb-628e431ec758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Get started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications\n",
      "---------------------------------------------------------------\n",
      ". Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in _docs:\n",
    "    print(_.page_content)\n",
    "    print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe7ffe81-bede-430e-8907-bab770bdbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "Context: {context}\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b0433e5c-c42a-4937-8f2d-0511823cfdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), config={'run_name': 'format_inputs'})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], template='Answer the following question based only on the provided context:\\nContext: {context}\\nQuestion: {input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000208EE60BC90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000208E51849D0>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser(), config={'run_name': 'stuff_documents_chain'})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "382acb84-44f8-4cb7-835b-a56e9793a1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing users to visualize test results.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b3ae9d5-a521-4ede-a5bf-93a90d31cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d3ea828-f7b9-462f-9247-d8dee0c7124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'context': [Document(page_content='. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1', metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       "  Document(page_content='\\n\\n\\n\\n\\nGet started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentLangSmith API DocsSearchGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications', metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       "  Document(page_content='. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langchain langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3', metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'}),\n",
       "  Document(page_content='.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client', metadata={'source': 'https://docs.smith.langchain.com/', 'title': 'Get started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!', 'language': 'en'})],\n",
       " 'answer': 'LangSmith can help with testing by allowing you to closely monitor and evaluate your application, so you can ship quickly and with confidence. It provides a platform for building production-grade LLM applications and offers features such as creating API keys and defining datasets for test cases. LangSmith works on its own, so the use of LangChain is not necessary.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "149becd2-d142-46cb-89dd-6e78ca433fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith can help with testing by allowing you to closely monitor and evaluate your application, so you can ship quickly and with confidence. It provides a platform for building production-grade LLM applications and offers features such as creating API keys and defining datasets for test cases. LangSmith works on its own, so the use of LangChain is not necessary.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca743e-db7b-4aab-a7ce-b4f27d6974ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
